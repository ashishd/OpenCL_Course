{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da6d105-2df5-40a6-9baa-02497fcef0d8",
   "metadata": {},
   "source": [
    "# Measuring peformance in OpenCL applications\n",
    "\n",
    "Having an understanding of how well OpenCL applications perform is a vital part of the development process. The two main tools, **profiling** and **tracing** collect information about how well an application is performing. **Profiling** is the statistical collection of the cumulative time that threads spend in each program component. **Tracing** is the collection of both **when** and **for how long** threads spend in each application component. While it is true that many vendors have largely abandoned their OpenCL performance measurement tools, the OpenCL standard itself provides a profiling interface and there are still a few open-source and commercial tools available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d07024-044f-4c11-a9e9-2c94222ca25d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Event based profiling\n",
    "\n",
    "Command queues have the ability to capture timing information for commands they process. In order to time commands submitted to an OpenCL command queue we enable a profiling flag **CL_QUEUE_PROFILING_ENABLE** during command queue creation. The time elap elapsed may be extracted directly from profiling events. In the code [mat_mult_profiling.cpp](mat_mult_profiling.cpp) we set the profiling flag to CL_TRUE.\n",
    "\n",
    "```C++\n",
    "    // mat_mult_profiling.cpp source\n",
    "\n",
    "    // Do we enable profiling?\n",
    "    cl_bool profiling = CL_TRUE;\n",
    "```\n",
    "\n",
    "Then from within **h_create_command_queues** in <a href=\"../include/cl_helper.hpp\">cl_helper.hpp</a>, the profiling flag CL_QUEUE_PROFILING_ENABLE is incorporated into the command queue properties and passed to [clCreateCommandQueue](https://www.khronos.org/registry/OpenCL/sdk/3.0/docs/man/html/clCreateCommandQueue.html).\n",
    "\n",
    "```C++\n",
    "    // cl_helper.hpp source\n",
    "\n",
    "    // Manage bit fields for the command queue properties\n",
    "    if (profiling_enable == CL_TRUE) {\n",
    "        queue_properties = queue_properties | CL_QUEUE_PROFILING_ENABLE;    \n",
    "    }\n",
    "\n",
    "    // Allocate memory for the command queues\n",
    "    cl_command_queue *command_queues = (cl_command_queue*)calloc(num_command_queues, sizeof(cl_command_queue));\n",
    "\n",
    "    // Fill command queues in a Round-Robin fashion\n",
    "    for (cl_uint n=0; n<num_command_queues; n++) {\n",
    "        command_queues[n] = clCreateCommandQueue(\n",
    "            contexts[n % num_devices],\n",
    "            devices[n % num_devices],\n",
    "            queue_properties,\n",
    "            &errcode    \n",
    "        );\n",
    "        h_errchk(errcode, \"Creating a command queue\");        \n",
    "    }\n",
    "```\n",
    "\n",
    "The function [clGetEventProfilingInfo](https://www.khronos.org/registry/OpenCL/sdk/3.0/docs/man/html/clGetEventProfilingInfo.html) extracts information such as start and end walltimes (in nanoseconds) for an OpenCL event associated with a queued command. We use the helper function **h_get_event_time_ms** in <a href=\"../include/cl_helper.hpp\">cl_helper.hpp</a> to extract the elapsed time.\n",
    "\n",
    "```C++\n",
    "\n",
    "// cl_helper.hpp source\n",
    "\n",
    "cl_double h_get_event_time_ms(\n",
    "        cl_event *event, \n",
    "        const char* message, \n",
    "        size_t* nbytes) {\n",
    "    \n",
    "    // Make sure the event has finished\n",
    "    h_errchk(clWaitForEvents(1, event), message);\n",
    "    \n",
    "    // Start and end times\n",
    "    cl_ulong t1, t2;\n",
    "        \n",
    "    // Fetch the start and end times in nanoseconds\n",
    "    h_errchk(\n",
    "        clGetEventProfilingInfo(\n",
    "            *event,\n",
    "            CL_PROFILING_COMMAND_START,\n",
    "            sizeof(cl_ulong),\n",
    "            &t1,\n",
    "            NULL\n",
    "        ),\n",
    "        \"Fetching start time for event\"\n",
    "    );\n",
    "\n",
    "    h_errchk(\n",
    "        clGetEventProfilingInfo(\n",
    "            *event,\n",
    "            CL_PROFILING_COMMAND_END,\n",
    "            sizeof(cl_ulong),\n",
    "            &t2,\n",
    "            NULL\n",
    "        ),\n",
    "        \"Fetching end time for event\"\n",
    "    );\n",
    "    \n",
    "    // Convert the time into milliseconds\n",
    "    cl_double elapsed = (cl_double)(t2-t1)*(cl_double)1.0e-6;\n",
    "        \n",
    "    // Print the timing message if necessary\n",
    "    if (strlen(message)>0) {\n",
    "        std::printf(\"Time for event \\\"%s\\\": %.3f ms\", message, elapsed);\n",
    "        \n",
    "        // Print transfer rate if nbytes is specified\n",
    "        if (nbytes != NULL) {\n",
    "            cl_double io_rate_MBs = h_get_io_rate_MBs(\n",
    "                elapsed, \n",
    "                *nbytes\n",
    "            );\n",
    "            std::printf(\" (%.2f MB/s)\", io_rate_MBs);\n",
    "        }\n",
    "        std::printf(\"\\n\");\n",
    "    }\n",
    "    \n",
    "    return elapsed;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41146a0-7600-407e-899d-43a26344927c",
   "metadata": {},
   "source": [
    "Every command submitted to a command queue may have an event associated with it. \n",
    "\n",
    "### Instrumenting the buffer copy\n",
    "\n",
    "We construct a **cl_event** object and use that event to collect timing information. For example, during writes to a device buffer we pass in a **cl_event** object to collect timing information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521d954-f071-4bdb-8b9f-1e87469eff0d",
   "metadata": {},
   "source": [
    "```C++\n",
    "    // mat_mult.cpp source\n",
    "   cl_event io_event;\n",
    "\n",
    "    H_ERRCHK(\n",
    "        clEnqueueWriteBuffer(\n",
    "            command_queue,\n",
    "            A_d,\n",
    "            blocking,\n",
    "            0,\n",
    "            nbytes_A,\n",
    "            A_h,\n",
    "            0,\n",
    "            NULL,\n",
    "            &io_event\n",
    "        ) \n",
    "    );\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99abd7-4aae-4c72-86b6-5f216b7ac590",
   "metadata": {},
   "source": [
    "Then, we use **h_get_event_time_ms** to extract the elapsed time and print out the transfer rate.\n",
    "\n",
    "```C++\n",
    "    // Time how long it takes to complete event\n",
    "    cl_double upload_A_ms = h_get_event_time_ms(\n",
    "        &io_event, \n",
    "        \"Uploading Buffer A\",\n",
    "        &nbytes_A\n",
    "    );\n",
    "```\n",
    "\n",
    "The buffer copies from **B_h** to **B_d**, and then from **C_d** to **C_h** are also instrumented in a similar way. From the previous call to **h_get_event_time_ms** we know **io_event** is in a complete state, so we can reuse it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06f835-46d4-4860-b3a9-1479d730be2d",
   "metadata": {},
   "source": [
    "### Instrumenting the kernel\n",
    "\n",
    "Similarly, the **[clEnqueueNDRangeKernel](https://www.khronos.org/registry/OpenCL/sdk/3.0/docs/man/html/clEnqueueNDRangeKernel.html)** command accepts an OpenCL Event. \n",
    "\n",
    "```C++\n",
    "    // Event for the kernel\n",
    "    cl_event kernel_event;\n",
    "    \n",
    "    // Now enqueue the kernel\n",
    "    H_ERRCHK(\n",
    "        clEnqueueNDRangeKernel(\n",
    "            command_queue,\n",
    "            kernel,\n",
    "            work_dim,\n",
    "            NULL,\n",
    "            global_size,\n",
    "            local_size,\n",
    "            0,\n",
    "            NULL,\n",
    "            &kernel_event\n",
    "        ) \n",
    "    );\n",
    "\n",
    "    // Time how long it takes to complete event\n",
    "    cl_double run_kernel_ms = h_get_event_time_ms(\n",
    "        &kernel_event, \n",
    "        \"Running kernel\",\n",
    "        NULL\n",
    "    );\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd3ff9-409d-4f1a-a692-24e512e58bcb",
   "metadata": {},
   "source": [
    "In this manner we instrument the uploads, downloads, and kernel execution in the source file [mat_mult_profiling.cpp](mat_mult_profiling.cpp). Now we run the instrumented code and print out the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64468ad-d6f3-4b8a-9fa9-5d7fd74a28c0",
   "metadata": {},
   "source": [
    "## Compile and run the appliciation\n",
    "\n",
    "The makefile is set to compile the example [mat_mult.cpp](mat_mult.cpp). The program creates and fills matrices **A** and **B** with random numbers in the range [0-1] and then uses HIP to compute the solution in matrix **C**. The matrices are written to the following files in binary format:\n",
    "\n",
    "* arrayA.dat\n",
    "* arrayB.dat\n",
    "* arrayC.dat\n",
    "\n",
    "On your terminal change directory to **L3_Matrix_Multiplication** and compile and run with these commands (without the exclamation mark !)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63b5c7f6-00d0-4630-bae7-79209769b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -r *.exe\n",
      "g++ -std=c++11 -g -O2 -fopenmp -I/usr/include -I../include -L/usr/lib/x86_64-linux-gnu mat_mult_profiling.cpp\\\n",
      "\t-o mat_mult_profiling.exe -lOpenCL\n",
      "In file included from \u001b[01m\u001b[Kmat_mult_profiling.cpp:18\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../include/cl_helper.hpp:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[K_cl_command_queue** h_create_command_queues(_cl_device_id**, _cl_context**, cl_uint, cl_uint, cl_bool, cl_bool)\u001b[m\u001b[Kâ€™:\n",
      "\u001b[01m\u001b[K../include/cl_helper.hpp:337:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[K_cl_command_queue* clCreateCommandQueue(cl_context, cl_device_id, cl_command_queue_properties, cl_int*)\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  337 |         command_queues[n] = \u001b[01;35m\u001b[KclCreateCommandQueue(\u001b[m\u001b[K\n",
      "      |                             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
      "  338 | \u001b[01;35m\u001b[K            contexts[n % num_devices],\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K           \n",
      "  339 | \u001b[01;35m\u001b[K            devices[n % num_devices],\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K            \n",
      "  340 | \u001b[01;35m\u001b[K            queue_properties,\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                    \n",
      "  341 | \u001b[01;35m\u001b[K            &errcode\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~\u001b[m\u001b[K                             \n",
      "  342 | \u001b[01;35m\u001b[K        )\u001b[m\u001b[K;\n",
      "      |         \u001b[01;35m\u001b[K~\u001b[m\u001b[K                                        \n",
      "In file included from \u001b[01m\u001b[K../include/CL/opencl.h:24\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K../include/cl_helper.hpp:25\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kmat_mult_profiling.cpp:18\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../include/CL/cl.h:1913:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " 1913 | \u001b[01;36m\u001b[KclCreateCommandQueue\u001b[m\u001b[K(cl_context                     context,\n",
      "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "g++ -std=c++11 -g -O2 -fopenmp -I/usr/include -I../include -L/usr/lib/x86_64-linux-gnu mat_elementwise.cpp\\\n",
      "\t-o mat_elementwise.exe -lOpenCL\n",
      "In file included from \u001b[01m\u001b[Kmat_elementwise.cpp:15\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../include/cl_helper.hpp:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[K_cl_command_queue** h_create_command_queues(_cl_device_id**, _cl_context**, cl_uint, cl_uint, cl_bool, cl_bool)\u001b[m\u001b[Kâ€™:\n",
      "\u001b[01m\u001b[K../include/cl_helper.hpp:337:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[K_cl_command_queue* clCreateCommandQueue(cl_context, cl_device_id, cl_command_queue_properties, cl_int*)\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  337 |         command_queues[n] = \u001b[01;35m\u001b[KclCreateCommandQueue(\u001b[m\u001b[K\n",
      "      |                             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
      "  338 | \u001b[01;35m\u001b[K            contexts[n % num_devices],\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K           \n",
      "  339 | \u001b[01;35m\u001b[K            devices[n % num_devices],\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K            \n",
      "  340 | \u001b[01;35m\u001b[K            queue_properties,\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                    \n",
      "  341 | \u001b[01;35m\u001b[K            &errcode\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~\u001b[m\u001b[K                             \n",
      "  342 | \u001b[01;35m\u001b[K        )\u001b[m\u001b[K;\n",
      "      |         \u001b[01;35m\u001b[K~\u001b[m\u001b[K                                        \n",
      "In file included from \u001b[01m\u001b[K../include/CL/opencl.h:24\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K../include/cl_helper.hpp:25\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kmat_elementwise.cpp:15\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../include/CL/cl.h:1913:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " 1913 | \u001b[01;36m\u001b[KclCreateCommandQueue\u001b[m\u001b[K(cl_context                     context,\n",
      "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "g++ -std=c++11 -g -O2 -fopenmp -I/usr/include -I../include -L/usr/lib/x86_64-linux-gnu mat_elementwise_answers.cpp\\\n",
      "\t-o mat_elementwise_answers.exe -lOpenCL\n",
      "In file included from \u001b[01m\u001b[Kmat_elementwise_answers.cpp:15\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../include/cl_helper.hpp:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[K_cl_command_queue** h_create_command_queues(_cl_device_id**, _cl_context**, cl_uint, cl_uint, cl_bool, cl_bool)\u001b[m\u001b[Kâ€™:\n",
      "\u001b[01m\u001b[K../include/cl_helper.hpp:337:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[K_cl_command_queue* clCreateCommandQueue(cl_context, cl_device_id, cl_command_queue_properties, cl_int*)\u001b[m\u001b[Kâ€™ is deprecated [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wdeprecated-declarations\u0007-Wdeprecated-declarations\u001b]8;;\u0007\u001b[m\u001b[K]\n",
      "  337 |         command_queues[n] = \u001b[01;35m\u001b[KclCreateCommandQueue(\u001b[m\u001b[K\n",
      "      |                             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~^\u001b[m\u001b[K\n",
      "  338 | \u001b[01;35m\u001b[K            contexts[n % num_devices],\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K           \n",
      "  339 | \u001b[01;35m\u001b[K            devices[n % num_devices],\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K            \n",
      "  340 | \u001b[01;35m\u001b[K            queue_properties,\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                    \n",
      "  341 | \u001b[01;35m\u001b[K            &errcode\u001b[m\u001b[K\n",
      "      |             \u001b[01;35m\u001b[K~~~~~~~~\u001b[m\u001b[K                             \n",
      "  342 | \u001b[01;35m\u001b[K        )\u001b[m\u001b[K;\n",
      "      |         \u001b[01;35m\u001b[K~\u001b[m\u001b[K                                        \n",
      "In file included from \u001b[01m\u001b[K../include/CL/opencl.h:24\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[K../include/cl_helper.hpp:25\u001b[m\u001b[K,\n",
      "                 from \u001b[01m\u001b[Kmat_elementwise_answers.cpp:15\u001b[m\u001b[K:\n",
      "\u001b[01m\u001b[K../include/CL/cl.h:1913:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n",
      " 1913 | \u001b[01;36m\u001b[KclCreateCommandQueue\u001b[m\u001b[K(cl_context                     context,\n",
      "      | \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
      "\t               name: NVIDIA GeForce RTX 3060 Laptop GPU \n",
      "\t global memory size: 6226 MB\n",
      "\t    max buffer size: 1556 MB\n",
      "\t     max local size: (1024,1024,64)\n",
      "\t     max work-items: 1024\n",
      "Time for event \"Uploading Buffer A\": 0.042 ms (12809.85 MB/s)\n",
      "Time for event \"Uploading Buffer B\": 0.042 ms (25422.63 MB/s)\n",
      "Time for event \"Running kernel\": 0.442 ms\n",
      "Time for event \"Downloading Buffer C\": 0.184 ms (11676.24 MB/s)\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n"
     ]
    }
   ],
   "source": [
    "!make clean; make; ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a4568-4ac0-4def-9b6d-f0ddc7494176",
   "metadata": {},
   "source": [
    "## Open-source profiling tools\n",
    "\n",
    "### Tau\n",
    "\n",
    "[Tau](https://www.cs.uoregon.edu/research/tau/home.php) is a commonly used open-source profiling and tracing toolkit for HPC applications. For OpenCL applications it provides both profiling and tracing functionality.\n",
    "\n",
    "#### Profiling\n",
    "\n",
    "The Tau application **tau_exec** can be used to collect profiling information. Profiling information can then be visualised with the Tau applications **paraprof** (GUI), or **pprof** (command-line).\n",
    "\n",
    "We set the environment variables **PROFILEDIR=./tau** to tell Tau where to put files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7832d88-f179-467a-a1ee-edb71269b417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROFILEDIR=./tau\n"
     ]
    }
   ],
   "source": [
    "%env PROFILEDIR=./tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5afba1d-97d2-45b1-9f6b-d73b91b72fee",
   "metadata": {},
   "source": [
    "Then we use the following call to **tau_exec** to collect profiling information for opencl calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690edd47-7197-4853-a63a-ab9ad86bd26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t               name: NVIDIA GeForce RTX 3060 Laptop GPU \n",
      "\t global memory size: 6226 MB\n",
      "\t    max buffer size: 1556 MB\n",
      "\t     max local size: (1024,1024,64)\n",
      "\t     max work-items: 1024\n",
      "device id: 181352528.\n",
      "command id: 93995599091328.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 2 .TAU application\n",
      "Time for event \"Uploading Buffer A\": 0.041 ms (12879.26 MB/s)\n",
      "Time for event \"Uploading Buffer B\": 0.041 ms (25560.37 MB/s)\n",
      "Time for event \"Running kernel\": 0.437 ms\n",
      "Time for event \"Downloading Buffer C\": 0.213 ms (10094.81 MB/s)\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n"
     ]
    }
   ],
   "source": [
    "!tau_exec -T serial -opencl ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9338d-2708-4b49-99c8-90402390ffeb",
   "metadata": {},
   "source": [
    "Now have a look at the contents of the tau directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d759662c-caf0-4a14-b1c6-372512ba1ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events.0.edf   profile.0.0.2  tautrace.0.0.0.trc  tau.trc\n",
      "profile.0.0.0  profile.txt    tautrace.0.0.1.trc  trace.json\n",
      "profile.0.0.1  tau.edf\t      tautrace.0.0.2.trc\n"
     ]
    }
   ],
   "source": [
    "!ls ./tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e657c280-402b-434a-bb02-5aa1599fe54e",
   "metadata": {},
   "source": [
    "Use the Tau application **pprof** to get a text mode profile of the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc64ec07-40a3-4fc4-88e0-530a95acf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pprof > ./tau/profile.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adde27b-0d4f-440d-a042-bc8792ec5da3",
   "metadata": {},
   "source": [
    "We see from the profile that the call to **mat_mult** took approximately **12ms**. This is similar to what was measured from the profiling interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2c5862-a647-4d86-909d-2522b8852954",
   "metadata": {},
   "source": [
    "#### Tracing with Google Chrome tracing\n",
    "\n",
    "For tracing we set the environment variables **TRACEDIR=./tau** **TAU_TRACE=1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a356019-c905-49c6-991e-ad2298b4d647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TAU_TRACE=1\n",
      "env: TRACEDIR=./tau\n"
     ]
    }
   ],
   "source": [
    "%env TAU_TRACE=1\n",
    "%env TRACEDIR=./tau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759ad7a-189f-4040-abcd-ae34777a5372",
   "metadata": {},
   "source": [
    "Capture OpenCL information as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c6b2ec1-47c5-4990-928c-be2ca33707e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t               name: NVIDIA GeForce RTX 3060 Laptop GPU \n",
      "\t global memory size: 6226 MB\n",
      "\t    max buffer size: 1556 MB\n",
      "\t     max local size: (1024,1024,64)\n",
      "\t     max work-items: 1024\n",
      "device id: 478091040.\n",
      "command id: 94395327787920.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 2 .TAU application\n",
      "Time for event \"Uploading Buffer A\": 0.041 ms (12889.23 MB/s)\n",
      "Time for event \"Uploading Buffer B\": 0.041 ms (25580.17 MB/s)\n",
      "Time for event \"Running kernel\": 0.449 ms\n",
      "Time for event \"Downloading Buffer C\": 0.202 ms (10600.51 MB/s)\n",
      "Maximum error (infinity norm) is: 2.28882e-05\n"
     ]
    }
   ],
   "source": [
    "!tau_exec -T serial -opencl ./mat_mult_profiling.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fa4a15-cd9f-4fe7-a327-c13ed2fc8a58",
   "metadata": {},
   "source": [
    "Now merge the trace into a downloadable JSON document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef2b39c5-095f-4a1d-a5bb-5f1f832c2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tau/2.31.1/x86_64/bin/tau_merge -m tau.edf -e events.0.edf events.0.edf events.0.edf tautrace.0.0.0.trc tautrace.0.0.1.trc tautrace.0.0.2.trc tau.trc\n",
      "tau.trc exists; override [y]? tautrace.0.0.0.trc: 450 records read.\n",
      "tautrace.0.0.1.trc: 6 records read.\n",
      "tautrace.0.0.2.trc: 41 records read.\n"
     ]
    }
   ],
   "source": [
    "!cd tau; echo 'y' | tau_treemerge.pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d8aa57a-1fc3-4881-9214-46f172cdb212",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd tau; tau_trace2json ./tau.trc ./tau.edf -chrome -ignoreatomic -o trace.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69b24f-2aa5-45ba-82de-a08138bb4bb7",
   "metadata": {},
   "source": [
    "Using the file manager on the left download the file in **tau/trace.json** to your computer. Then in your browser you can go to the address [https://ui.perfetto.dev](https://ui.perfetto.dev) and load the trace for viewing on your local machine. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214adcb4-922f-4b26-b426-76207b50f0aa",
   "metadata": {},
   "source": [
    "<figure style=\"margin-left:0; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/Chrome_trace.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Tracing OpenCL calls with <a href=\"https://ui.perfetto.dev\">ui.perfetto.dev</a>.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c65792d-d382-4dfb-8dbb-484d861fa839",
   "metadata": {},
   "source": [
    "In this instance we see that the kernel **mat_mult** has taken approximately 0.45ms to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c769e69-47de-4514-8c95-0cec4302a0df",
   "metadata": {},
   "source": [
    "## Commercial profiling tools\n",
    "\n",
    "### CLTracer\n",
    "\n",
    "[CLTracer](https://www.cltracer.com/) is a commerical product that profiles OpenCL calls for Windows and Linux OpenCL applications. It requires a GUI to run and provides \n",
    "\n",
    "* A timeline of OpenCL calls, separated into API and kernel calls\n",
    "* Tables of time spent in each call\n",
    "    * Global and local kernel size recorded\n",
    "    * Size of transfers recorded\n",
    "* Time spent in the API vs time spent blocking\n",
    "* Breakdown of time spent in kernels\n",
    "* Breakdown of time spent in queues\n",
    "\n",
    "Setting up project settings and running a trace for [mat_mult_profiling.cpp](mat_mult_profiling.cpp) was really easy. Unfortunately I don't see the ability to fetch information from the command line.\n",
    "\n",
    "#### Timeline view\n",
    "\n",
    "The timeline view shows when and for how long each OpenCL call lasts. The overview shows that setting \n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/cltracer_timeline_overview.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">CLTracer timeline overview.</figcaption>\n",
    "</figure>\n",
    "\n",
    "If we zoom in to the kernel region we see that executing the kernel only took around 2.9ms and that it takes less time to upload and download arrays than the kernel spends executing.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/cltracer_timeline_zoom.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">CLTracer timeline, zoomed in on kernel region.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eedb5c-6b8c-4319-bad5-314a2f25cfe8",
   "metadata": {},
   "source": [
    "#### Tables\n",
    "\n",
    "The timeline can also be viewed in tabular format. In addition to times for each OpenCL call you can see global and local sizes of the kernels as well as the size of kernel uploads and downloads.\n",
    "\n",
    "<figure style=\"margin-left:auto; margin-right:auto; width:100%;\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/cltracer_tables.png\">\n",
    "    <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">CLTracer table of OpenCL calls.</figcaption>\n",
    "</figure>\n",
    "\n",
    "For more information on available tools within CLTracer please see the CLTracer [Documentation](https://www.cltracer.com/docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab4031c-f99a-4964-af68-d6b5fca975db",
   "metadata": {},
   "source": [
    "## Vendor profiling tools\n",
    "\n",
    "### AMD\n",
    "\n",
    "#### HSA application traces\n",
    "\n",
    "The AMD utility **rocprof** has the ability to collect traces \n",
    "\n",
    "```bash\n",
    "rocprof --hsa-trace -o rocprof_trace/result.csv ./mat_mult_profiling.exe\n",
    "```\n",
    "\n",
    "Then copy the file **rocprof_trace/result.json** back to your computer and go to the address\n",
    "\n",
    "[https://ui.perfetto.dev](https://ui.perfetto.dev)\n",
    "\n",
    "to load **result.json** and display the HSA trace. This is of limited utility as you'll need to guess which HSA calls correspond to OpenCL calls. \n",
    "\n",
    "#### Performance counters\n",
    "\n",
    "Rocprof can collect performance counters on kernels. We specify a list of counters and the kernels they should apply to in the file **[rocprof_counters.txt](rocprof_counters.txt)**\n",
    "\n",
    "```bash\n",
    "rocprof -i rocprof_counters.txt --timestamp on --stats -o rocprof_counters/result.csv ./mat_mult_profiling.exe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342ee5a-80fc-4176-93d3-85f4c5fde70f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NVIDIA\n",
    "\n",
    "#### Profiling with nvprof\n",
    "\n",
    "Historically there was limited functionality for profiling OpenCL events with NVIDIA's [NVVP](http://uob-hpc.github.io/2015/05/27/nvvp-import-opencl.html), however profiling support for OpenCL has largely disappeared, with the implementation of Nsight Compute and Nsight systems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38c04c-7c8d-4646-a382-0b02fb91a42e",
   "metadata": {},
   "source": [
    "<address>\n",
    "Written by Dr. Toby Potter of <a href=\"https://www.pelagos-consulting.com\">Pelagos Consulting and Education</a> for the Pawsey Supercomputing Centre\n",
    "</address>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104e1ea-af2e-4cef-8c0d-434c275882ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
